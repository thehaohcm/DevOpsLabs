Preparing short-command before taking the exam:

alias ks="kubectl -n kube-system"

alias kgp="kubectl get pod"
alias kgd="kubectl get deploy"
alias kgs="kubectl get service"
alias kgn="kubectl get node"
alias kd="kubectl describe"
alias kge="kubectl get events --sort-by='.metadata.creationTimestamp' | tail -8"

export dy="--dry-run=client -oyaml"

export now="--force --grace-period 0"

echo "set ts=2 sts=2 sw=2 et" >> ~/.vimrc

create new user:
  kubectl config set-credentials [user_name] --client-certificate=[.crt_path] --client-key=[.key_path]

create new context:
  kubectl config set-context [context_name] --user=[user_name] --cluster=[cluster_name]

switch context:
  kubectl config use-context [context_name]

CSR:
  create new csr with yaml format
  kubectl certificate approve [csr_name] 
  create new role
  create new rolebinding

run temporary pod (and it will be removed after done) and run a command:
  kubectl run [pod_name] --image=[image_name] --rm -ti --command -- [command]
or kubectl -it  run busybox --rm --image=busybox -- sh
ex: kubectl run test --image=busybox --rm -ti --command -- sleep 4600


collect osImage item of all ndoes by using jsonpath:
  kubectl get nodes -o jsonpath="{.item[*].status.nodeInfo.osImage}"
or we can use jq tool to show json with pretty format:
  kubectl get nodes -o jsonpath | jq
otherwise: 
  kubectl get nodes -o json | jq -c 'path(..)|[.[]|tostring]|join(".")' | grep -i osImage | grep -v managedFields
install jq tool: 
  apt install jq

get resources in k8s cluster and sort by creation time:
  kubectl api-resources --sort-by='.metadata.creationTime'

create a new service account
kubectl create sa [service_account_name]

add serviceaccount for a pod (yaml file)
spec:
  serviceAccount: [service_account_name]
  
create role:
  kubectl create role [role_name] [-n [namespace]] --verb=[create,update,delete,...] --resource=[pod,configmaps,secrets]
create rolebinding:
  kubectl create rolebinding [role_binding_name] [-n [namespace]] --role=[role_name] [--serviceaccount=[namespace]:[serviceaccount_name]] [--user=[user_name]]
check auth:
  kubectl auth can-i [verb] [resource] --as=system:serviceaccount:[namespace]:[service_account_name]
  
get all resource in k8s cluster:
  kubectl api-resources
  
check network plugin info:
  find /etc/cni/net.d/
  then read a file inside this folder

create a secret:
  kubectl create secret generic [secret_name] --from-literal=[key1]=[value1] --from-literal=[key2]=[value2]...
  
get cluster cidr network (2 ways):
  - kubectl cluster-info dump | grep -i 'cluster-ip-range'
  - cat /etc/kubernetes/manifest/kube-apiserver.yaml | grep -i 'cluster-ip-range'
  
join a node worker into cluster:
  run this comment in the master node (ssh into master node):
    kubeadm token create --print-join-command
  ssh into the new one worker node:
    then copy the join command in the master node and past into the worker node
    
get cert info of k8s clusters (server, client cert...):
  openssl x509 -noout -text -in [path of the cert file]
   ex: openssl x509 -noout -text -in /etc/kubernetes/pki/server.crt | grep -i 'After' -A3
  kubeadm certs check-expiration
  
  client certificate: /etc/kubernetes/kubelet.conf
  
renew cert with command
  kubeadm certs renew [service]
  ex: kubeadm certs renew apiserver
  
livenessProbe: check if container is available and 
readinessProd: check if the app is ready to be used serve traffic

monitor resource in:
  - nodes: kubectl top nodes
  - pod: kubectl top pods
  - pod + pod's containers: kubectl top pods --containers
  - specifc pod + pods containers: kubectl top pods [pod_name] --containers
  
create a snapshot with ectdctl
  ETCDCTL_API=3 etcdctl --endponint=[endpoint_URL:127.0.0.1]:2379 \
  --cert-file=[server.crt file path | /etc/kubernetes/pki/etcd/server.crt] \
  --key-file=[server.key file path | /etc/kubernentes/pki/etcd/server.key] \
  --trusted-ca-file=[ca.crt file path | /etc/kubernetes/pki/etcd/ca.crt] \
  snapshot save [path of a new snapshot file]
  
  - or we can config all above parameters by a way:
     + check status of etcd process by cmd: systemctl status ectd, then get its config file path. Usually, it is /etc/ectd/etcd.conf, or we can check its info in file path /etc/systemd/system/ectd
     + change the path of parameters, then save this file
     + run a simpler command: ETCDCTL_API=3 ectd snapshot save [path of a new snapshot file]
  
tips:
  if a question is asking for inspect to a container of pod:
    - find which node that the pod is running inside
    - ssh into the node
    - use 'crictl ps | grep [pod_name]' to check and get pod's container_id and info
      use 'crictl inspect [pod_ip]' to get info about the container
    (use crictl command as a docker command alter)
    
  if a question asking for create a deployment which only allow one pod will be run inside one node (include master node):
    - use affinity + podAntiAffinity + (topologyKey: kubernetes.io/hostname): to make sure no node has 2 the same pod running inside
    - use toleration to run a pod in the master node (copy a declaration in daemonset k8s doc)
  => this deployment will behave as a daemonset  
  
  how to specify a pod to run a specific node:
  1. use spec.nodeName
  2. use spec.nodeSelector (with node's label)
  3. use nodeAffinity
  4. use podAffinity 
  4. use podAntiAffinity + (topologyKey: kubernete.io/hostname)
  
  How to get kubernetes manifest folder path (for static pods):
    - ps aux | grep kubelet | grep -i '--config='
    
  if a question require to create a shared volume 
    => create an emptyDir{} in volumes section in yaml file
    
  if we have to define a chain of command line in a container of pod, we have to add "/bin/sh" and "-c" command into the command section
  ex:
    command:
    - "/bin/sh"
    - "-c"
    - "echo...; echo...; echo..."
    
  if a question ask to create a pod with running a while time when initializing => use command sleep 1d 
  ex:
    kubectl run [pod_name] --image=busybox [--dry-run=client -oyaml > [yaml file]] --command -- sleep 1d

linux stuff tips:
  find a text with insensitiy case:
    grep -i '[word]'
  find multi texts with insensity case:
    grep -i -e '^[word1]|[word2]'
  count line number:
    wc -l
  replace a word with another word:
    sed -i 's/[word1]/[word2]/g'
  check response of url:
    curl -s [url/pod_name/service_name/ip]:[port]
  get an absolute path of a file:
    readlink -f [file_name]
  get a specific column data:
    awk '{print $[column_num]}'
  encode data 
    echo -n "[word]" | base64
    (notice: "-n" paramter means don't print new line character)
  decode data
    echo "[word]" | base64 --decode

Notice:
  - If the nod is running out of resource, k8s will consider to terminate all pods that are using more than their request. That means all pod which doesn't have any "requests" section will be considered to terminated. To check them, just run command: 
    + kubectl describe pods | grep -e -i "^(name:| requests:)" -A1
    => all shown pods are pods that required resource, remove them from the considered list, then all the rest will be terminated
    + kubectl get pod -o jsonpath="{range .items[*]} {.metadata.name} {.spec.containers[*].resources}{'\n'}"
